services:
  kafka:
    image: confluentinc/cp-kafka:7.4.1
    container_name: ping_monkey_kafka
    restart: unless-stopped
    environment:
      # KRaft (no ZooKeeper)
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER

      # Listeners
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,EXTERNAL://0.0.0.0:29092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,EXTERNAL://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT

      # Single-node factors
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_NUM_PARTITIONS: 1

      # Dev convenience (set to "false" in prod)
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

      # Storage
      KAFKA_LOG_DIRS: /var/lib/kafka/data

      # Optional sizing (tune to your payloads)
      # KAFKA_MESSAGE_MAX_BYTES: 20971520
      # KAFKA_REPLICA_FETCH_MAX_BYTES: 20971520

    command:
      - bash
      - -lc
      - |
        if [ ! -f /var/lib/kafka/data/meta.properties ]; then
          mkdir -p /var/lib/kafka/data
          CLUSTER_ID=$$(kafka-storage random-uuid)
          kafka-storage format --ignore-formatted --cluster-id "$$CLUSTER_ID" --config /etc/kafka/kafka.properties
        fi
        /etc/confluent/docker/run
    ports:
      # Host clients use localhost:9092 -> container EXTERNAL:29092
      - "9092:29092"
      # Controller port (usually not needed externally; keep for debug)
      - "9093:9093"
    volumes:
      - kafka-data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "bash", "-c", "kafka-broker-api-versions --bootstrap-server localhost:9092 >/dev/null 2>&1"]
      interval: 10s
      timeout: 5s
      retries: 10

  kafdrop:
    image: obsidiandynamics/kafdrop:4.0.2
    container_name: ping_monkey_kafdrop
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_BROKERCONNECT: "kafka:9092"   # internal listener
      JVM_OPTS: "-Xms32M -Xmx512M"
      SERVER_SERVLET_CONTEXT_PATH: "/"
    ports:
      - "9000:9000"

volumes:
  kafka-data:

networks:
  default:
    name: ping_monkey_network
